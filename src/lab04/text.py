import re
import unicodedata


def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    """
    ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ñ‚ÐµÐºÑÑ‚:
    - ÐŸÑ€Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ Ðº casefold (Ð»ÑƒÑ‡ÑˆÐµ Ñ‡ÐµÐ¼ lower Ð´Ð»Ñ Ð®Ð½Ð¸ÐºÐ¾Ð´Ð°)
    - Ð—Ð°Ð¼ÐµÐ½ÑÐµÑ‚ Ð±ÑƒÐºÐ²Ñ‹ Ñ‘/Ð Ð½Ð° Ðµ/Ð•
    - Ð£Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð½ÐµÐ²Ð¸Ð´Ð¸Ð¼Ñ‹Ðµ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‰Ð¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹, Ð·Ð°Ð¼ÐµÐ½ÑÑ Ð¸Ñ… Ð½Ð° Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹
    - Ð¡Ñ…Ð»Ð¾Ð¿Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸ÐµÑÑ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð² Ð¾Ð´Ð¸Ð½
    """
    if casefold:
        text = text.casefold()
    
    if yo2e:
        text = text.replace('Ñ‘', 'Ðµ').replace('Ð', 'Ð•')
    
    # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÑŽÑ‰Ð¸Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ Ð½ÐµÐ²Ð¸Ð´Ð¸Ð¼Ñ‹Ðµ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð½Ð° Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹
    text = ''.join(char if char.isprintable() or char.isspace() else ' ' for char in text)
    
    # Ð¡Ñ…Ð»Ð¾Ð¿Ñ‹Ð²Ð°ÐµÐ¼ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð² Ð¾Ð´Ð¸Ð½
    text = re.sub(r'\s+', ' ', text)
    
    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ Ð¸ ÐºÐ¾Ð½Ñ†Ðµ
    return text.strip()
print('normalize')
print("ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t ->", normalize("ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t"))
print("\"Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°\" ->", normalize("Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°"))
print("\"Hello\r\nWorld\" ->", normalize("Hello\r\nWorld"))
print("\"  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  \" ->", normalize("  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  "))


def tokenize(text: str) -> list[str]:
    
    # Ð ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ð¾Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° ÑÐ»Ð¾Ð² (Ð±ÑƒÐºÐ²Ñ‹/Ñ†Ð¸Ñ„Ñ€Ñ‹/Ð¿Ð¾Ð´Ñ‡Ñ‘Ñ€ÐºÐ¸Ð²Ð°Ð½Ð¸Ðµ + Ð´ÐµÑ„Ð¸Ñ Ð²Ð½ÑƒÑ‚Ñ€Ð¸)
    pattern = r'[\w]+(?:-[\w]+)*'
    tokens = re.findall(pattern, text)
    
    return tokens
print('tokenize')
print("\"Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€\" ->", tokenize(("Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€")))
print("\"hello,world!!!\" ->", tokenize(("hello,world!!!")))
print("\"Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾\" ->", tokenize(("Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾")))
print("\"2025 Ð³Ð¾Ð´\" ->", tokenize(("2025 Ð³Ð¾Ð´")))
print("\"emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾\" ->", tokenize(("emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾")))

def count_freq(tokens: list[str]) -> dict[str, int]:
    """
    ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²
    """
    freq = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq



def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ‚Ð¾Ð¿-N Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð¿Ð¾ ÑƒÐ±Ñ‹Ð²Ð°Ð½Ð¸ÑŽ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹
    ÐŸÑ€Ð¸ Ñ€Ð°Ð²ÐµÐ½ÑÑ‚Ð²Ðµ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚ - Ð¿Ð¾ Ð°Ð»Ñ„Ð°Ð²Ð¸Ñ‚Ñƒ
    """
    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾ ÑƒÐ±Ñ‹Ð²Ð°Ð½Ð¸ÑŽ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹, Ð·Ð°Ñ‚ÐµÐ¼ Ð¿Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°Ð½Ð¸ÑŽ ÑÐ»Ð¾Ð²Ð° (Ð°Ð»Ñ„Ð°Ð²Ð¸Ñ‚Ñƒ)
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]
print('count_freq + top_n')
print('["a","b","a","c","b","a"] ->', count_freq((["a","b","a","c","b","a"])))
print('top_n(..., n=2) ->', top_n(count_freq((["a","b","a","c","b","a"]))))
print('["bb","aa","bb","aa","cc"] ->', count_freq((["bb","aa","bb","aa","cc"])))
print('top_n(..., n=2) ->', top_n(count_freq((["bb","aa","bb","aa","cc"]))))